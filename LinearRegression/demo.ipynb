{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston\n",
    "Boston is a famous dataset that is widely used in regression.Now let us train a small multi-linear regression model by Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression, we divide dataset to testset and train set, in order to evaluate the efficentcy on test set and get \n",
    "$$\\min MSE$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lyyus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comes linear regression, in dataset $D = \\{x_1,x_2,\\cdots,x_m\\},x_i = (x_{i1},x_{i2},\\cdots,x_{in})^T$, each $x_i$ has a label $y_i\\in \\mathbb{R}$, formed a label set $Y$. The target is to train a model to predict possible $\\hat{y}$ for the gained $x_i$, based on the dataset $D$ and $Y$, which is multi-linear in the form as follows:\n",
    "$$\\hat{y_i} = \\theta_0 + \\theta_1x_{1i} + \\theta_2x_{2i} + \\cdots + \\theta_nx_{ni}$$\n",
    "Let $\\hat{\\theta}$ be $(\\theta_0,\\theta_1,\\cdots,\\theta_n)^T$, and $\\hat{y}$ be $(\\hat{y_1},\\hat{y_2},\\cdots,\\hat{y_m})^T$, $X$ be\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & x_{11} & x_{12} & \\cdots & x_{1n}  \\\\\n",
    "1 & x_{21} & x_{22} & \\cdots & x_{2n}  \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots  \\\\\n",
    "1 & x_{m1} & x_{m2} & \\cdots & x_{mn}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "then\n",
    "$$\n",
    "\\hat{y} = X\\hat{\\theta}\n",
    "$$\n",
    "For each $x_i$, we get the true $y_i$, to evaluate the effiency of model,we can use MSE to get it. Obviously the best model is to minimize MSE.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    MSE &= \\frac{1}{m}\\sum_{i=1}^{m}(y_i - \\hat{y_i})^2 \\\\\n",
    "        &= \\frac{1}{m}(y - \\hat{y})(y - \\hat{y})^T\\\\\n",
    "        &= \\frac{1}{m}(y - X\\hat{\\theta})(y - X\\hat{\\theta})^T\n",
    "\\end{aligned}\n",
    "$$\n",
    "One method is precise. It is as follows. To get min MSE, we can do\n",
    "$$\n",
    "\\nabla_{\\hat{\\theta}} E_{\\hat{\\theta}} = \\frac{\\partial E_{\\hat{\\theta}}}{\\partial\\hat{\\theta}} = 2X^T(X\\hat{\\theta} - y) = 0\n",
    "$$\n",
    "in which $E_{\\hat{\\theta}} = (y - X\\hat{\\theta})(y - X\\hat{\\theta})^T$.\n",
    "Then get $\\hat{\\theta} = (X^TX)^{-1}X^Ty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method is Gradient Descent, for calculating $X^TX^{-1}$ is complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.99672362, 36.02556534, 14.81694405, 25.03197915, 18.76987992,\n",
       "       23.25442929, 17.66253818, 14.34119   , 23.01320703, 20.63245597,\n",
       "       24.90850512, 18.63883645, -6.08842184, 21.75834668, 19.23922576,\n",
       "       26.19319733, 20.64773313,  5.79472718, 40.50033966, 17.61289074,\n",
       "       27.24909479, 30.06625441, 11.34179277, 24.16077616, 17.86058499,\n",
       "       15.83609765, 22.78148106, 14.57704449, 22.43626052, 19.19631835,\n",
       "       22.43383455, 25.21979081, 25.93909562, 17.70162434, 16.76911711,\n",
       "       16.95125411, 31.23340153, 20.13246729, 23.76579011, 24.6322925 ,\n",
       "       13.94204955, 32.25576301, 42.67251161, 17.32745046, 27.27618614,\n",
       "       16.99310991, 14.07009109, 25.90341861, 20.29485982, 29.95339638,\n",
       "       21.28860173, 34.34451856, 16.04739105, 26.22562412, 39.53939798,\n",
       "       22.57950697, 18.84531367, 32.72531661, 25.0673037 , 12.88628956,\n",
       "       22.68221908, 30.48287757, 31.52626806, 15.90148607, 20.22094826,\n",
       "       16.71089812, 20.52384893, 25.96356264, 30.61607978, 11.59783023,\n",
       "       20.51232627, 27.48111878, 11.01962332, 15.68096344, 23.79316251,\n",
       "        6.19929359, 21.6039073 , 41.41377225, 18.76548695,  8.87931901,\n",
       "       20.83076916, 13.25620627, 20.73963699,  9.36482222, 23.22444271,\n",
       "       31.9155003 , 19.10228271, 25.51579303, 29.04256769, 20.14358566,\n",
       "       25.5859787 ,  5.70159447, 20.09474756, 14.95069156, 12.50395648,\n",
       "       20.72635294, 24.73957161, -0.164237  , 13.68486682, 16.18359697,\n",
       "       22.27621999, 24.47902364])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.291119474973232"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
